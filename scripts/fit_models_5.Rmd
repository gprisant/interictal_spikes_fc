---
title: "Do Interictal Discharges Affect iEEG Functional Connectivity"
output: html_document
author: Jennifer Stiso
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# clean workspace
rm(list=ls())

if (!require("pacman")) install.packages("pacman")
pacman::p_load(ggplot2, dplyr, lm.beta, RColorBrewer, nationalparkcolors, rjson, reticulate, gridExtra, wesanderson, MASS, outliers, lmerTest, stringr, lmPerm)

# set up python for later
use_python("/Users/stiso/anaconda3/bin/python") # path to python binary
py_config() # check it is using the specified version

# directory for RAM data, request from XXX
RAM_dir = '/Volumes/bassett-data/Jeni/RAM/'

# parameters
win = 1
detector = '_delphos'

```

## Functions
```{r}
get_beta <- function(d, ys, f) {
  # scale x's
  d['spike_num'] <- scale(d['spike_num'])
  d['power'] <- scale(d['power'])
  
  # fit models for every given predictor
  for (y in ys){
    # remove nan rows
    d_lm = d[!is.na(d[y]),]
    
    # check if multiple sess and exper
    if (length(unique(d_lm$sess_exper)) > 1) {
      f_full <- paste(f, 'sess_exper', sep = ' + ')
      # to prevent prevent factor level errors
      d_lm$sess_exper = as.factor(d_lm$sess_exper)
    } else {
      f_full <- f
    }
    
    beta_bin_name <- paste(y, 'beta_bin', sep = '_')
    beta_num_name <- paste(y, 'beta_num', sep = '_')
    if (dim(d_lm[y])[1] == 0){ # check for nans
      d[beta_bin_name] <- NaN
      d[beta_num_name] <- NaN
    } else {
      # scale y
      d_lm[y] <- scale(d_lm[y])
      
      # make spike a factor - prevent factor level errors
      d_lm$bin_spike <- as.factor(d_lm$bin_spike)
      # for debugging
      #print(paste(y, d_lm$band[1], d_lm$fc_measure[1], d_lm$region[1]))
      
      # fit
      # check for singular matrix (only two values for spike_num)
      if (length(unique(d_lm$spike_num)) > 2){
        try({fit <- rlm(as.formula(paste(y, f_full, sep='')), data=d_lm, maxit=500)
        d[beta_bin_name] <- fit$coefficients['bin_spikeTRUE']
        d[beta_num_name] <- fit$coefficients['spike_num']})
      } else {
        f_full <- str_remove(f_full, fixed("+ bin_spike"))
        try({fit <- rlm(as.formula(paste(y, f_full, sep='')), data=d_lm, maxit=500)
        d[beta_bin_name] <- fit$coefficients['bin_spikeTRUE']
        d[beta_num_name] <- NaN})
      }

    }
  }
  return(d)
}
```

# Methods

words

## Load Data

```{r}
# get subjects from all releases
releases <- c('1', '2', '3')
subj <- list()
for (r in releases){
  curr_info <- paste(RAM_dir, 'release', r, '/protocols/r1.json', sep='')
  df <- rjson::fromJSON(file = curr_info)
  df <- names(df$protocols$r1$subjects) %>%
    lapply(function(x){paste('release', r, '/r1/', x, sep ='')})
  subj <- append(subj, df)
}

```

## Fit Models

```{r}
# Do we want to make plots? faster if no
save_plot = FALSE

# intiialize, make constants
# constant fields
const_vars <- c('subj', 'hand', 'age', 'gender', 'race')
form <- ' ~ power + bin_spike + spike_num'
ys = c('str', 'str_soz', 'str_not_soz', 'str_spike', 'str_not_spike')

# final df
col_names <- c("fc_measure", "band", 'band_measure', "str_beta_bin", "str_beta_num", "subj", "hand", "age", "gender", "race", 'n_tp')
net_betas <- data.frame(matrix(ncol = length(col_names), nrow = 0))
colnames(net_betas) = col_names
col_names = c("subj", "fc_measure", "band", 'band_measure', "str_soz_beta_bin", "str_not_soz_beta_bin", "str_spike_beta_bin", 
              "str_not_spike_beta_bin","str_soz_beta_num", "str_not_soz_beta_num", "str_spike_beta_num", 'x', 'y', 'z', 'type',
              "str_not_spike_beta_num", "elec", "region", "n_tp", "elec_in_soz", "elec_spike", "age", "gender", "race", "hand" )
node_betas <- data.frame(matrix(ncol = length(col_names), nrow = 0))
colnames(node_betas) = col_names

# for each subject, load their data and fit some models
for (s in subj){
  # load strengths from matlab
  curr_csv <- paste(RAM_dir, 'FC/', s, '/win_', as.character(win), '/fc_data', detector, '.csv', sep = '')
  if (file.exists(curr_csv) ){
    node_data <- read.csv(curr_csv, header = TRUE, sep = ",", stringsAsFactors = FALSE,
                          colClasses=c(gender='character', hand='character', race='numeric', age='numeric', spike_num='numeric'))
    if (dim(node_data)[1] > 0){
      print(paste('Subj', s)) 
      # add band measure, combined string, for easy indexing (keep separate for plotting)
      node_data <- mutate(node_data, band_measure = paste(band, fc_measure, sep = '_'))
      # add sess_exper for model, dont actually want to model them separately
      node_data <- mutate(node_data, sess_exper = paste(sess, exper, sep = '_'))
      # add binary spike
      node_data$bin_spike = node_data$spike_num > 0
      # there shouldn't be any negative numbers, but if there are skip
      if (any(node_data$spike_num[complete.cases(node_data$spike_num)] < 0)){
        node_data$spike_num[node_data$spike_num < 0] = NaN
        warning("This dataset had negative spike numbers: check the spreadsheet")
        next
      }
      # there shouldn't be any NaNs, but if there are skip
      if (any(is.nan(node_data$spike_num)) | any(is.na(node_data$spike_num))){
        warning("This dataset had NaN spike numbers: check the spreadsheet")
        next
      }
      # log transform
      node_data$spike_num[node_data$spike_num != 0] = log10(node_data$spike_num[node_data$spike_num != 0])
      # drop hg phase locking - PLV not interpretable for wide band signals
      node_data <- filter(node_data, band_measure != "hg_plv")
      # remove duplicate time points, if present
      node_data <- node_data %>% distinct()
      
      # get network level strength separated by soz and not soz
      net_data <- group_by(node_data, sess_exper, time, spike_num, bin_spike, fc_measure, band, band_measure) %>%
        dplyr::summarise(str = mean(str, na.rm=TRUE), str_spike = mean(str_spike, na.rm=TRUE), 
                         str_not_spike = mean(str_not_spike, na.rm=TRUE), power = mean(power))
      # for soz networks, you can't average over all elecs, have to break them up
      tmp_soz = group_by(node_data, elec_in_soz, sess_exper, time, spike_num, bin_spike, fc_measure, band, band_measure) %>%
        dplyr::summarise(str_soz = mean(str_soz, na.rm=TRUE), str_not_soz = mean(str_not_soz, na.rm=TRUE))
      # remove not soz elecs from str_soz, and visa versa
      tmp_soz$str_soz[tmp_soz$elec_in_soz == 0] <- NA
      tmp_soz$str_not_soz[tmp_soz$elec_in_soz == 1] <- NA
      # now colapse over elec_in_soz
      tmp_soz <- group_by(node_data, sess_exper, time, spike_num, bin_spike, fc_measure, band, band_measure) %>%
        dplyr::summarise(str_soz = mean(str_soz, na.rm=TRUE), str_not_soz = mean(str_not_soz, na.rm=TRUE))
      # now merge on shared features (subj, band, time, etc)
      net_data = merge(net_data, tmp_soz, by = c('sess_exper', 'time', 'spike_num', 'bin_spike', "fc_measure", 'band', 'band_measure'))
      
      # add constants
      net_data[const_vars] = node_data[const_vars][1,]
      
      # plots
      if (save_plot){
          p1 <- ggplot(data=net_data[net_data$spike_num != 0,], aes(x=spike_num)) + geom_histogram() + theme_minimal()
          p2 <- ggplot(data=net_data[net_data$spike_num != 0,], aes(x=str, color=band, fill=as.factor(fc_measure))) + 
            geom_histogram(alpha=0.7) + theme_minimal() + scale_fill_manual(values=park_palette("Saguaro")) + scale_color_grey()
          p <- grid.arrange(p1, p2, nrow=2)
          ggsave(paste(RAM_dir, 'img/models/', net_data$subj, '_net_hist.png', sep=''), plot=p, device = 'png')
      }
    
      # for every fc_meansure and band, fit network model
      try({
        curr_net_beta <- group_by(net_data, band_measure) %>%
          group_modify(~ get_beta(.x,ys, form)) %>%
          dplyr::summarise(n_tp = length(time), str_beta_bin = str_beta_bin[1], str_beta_num = str_beta_num[1], 
                           str_soz_beta_bin = str_soz_beta_bin[1],  str_soz_beta_num = str_soz_beta_num[1],
                           str_not_soz_beta_num = str_not_soz_beta_num[1], str_spike_beta_num = str_spike_beta_num[1],
                           str_not_soz_beta_bin = str_not_soz_beta_bin[1], str_spike_beta_bin = str_spike_beta_bin[1],
                           str_not_spike_beta_bin = str_not_spike_beta_bin[1],fc_measure = fc_measure[1],
                           str_not_spike_beta_num = str_not_spike_beta_num[1], band = band[1])
        curr_net_beta[const_vars] <- net_data[const_vars][1,]
        
        # concatenate
        net_betas <- suppressWarnings(bind_rows(curr_net_beta, net_betas)) # silence warnings about converting factors to strings
      })
  
      # fit node models
      try({
          curr_node_beta <- group_by(node_data, elec, band_measure) %>%
              group_modify(~ get_beta(.x,ys, form)) %>%
              dplyr::summarise(n_tp = length(time), elec_spike = mean(elec_has_spike), elec_in_soz = elec_in_soz[1], str_soz_beta_bin = str_soz_beta_bin[1], 
                               str_not_soz_beta_bin = str_not_soz_beta_bin[1], str_spike_beta_bin = str_spike_beta_bin[1], 
                               str_not_spike_beta_bin = str_not_spike_beta_bin[1], str_beta_bin = str_beta_bin[1], str_soz_beta_num = str_soz_beta_num[1], 
                               str_not_soz_beta_num = str_not_soz_beta_num[1], str_spike_beta_num = str_spike_beta_num[1], str_beta_num = str_beta_num[1],
                               str_not_spike_beta_num = str_not_spike_beta_num[1], fc_measure = fc_measure[1], band = band[1], region = region[1], x = x[1],
                               y = y[1], z = z[1], type = type[1])
            curr_node_beta[const_vars] <- net_data[const_vars][1,]
            
          #  concetenate
          node_betas <- suppressWarnings(bind_rows(curr_node_beta, node_betas)) # silence warnings about converting factors to strings
        })
     }
  }
}

# save betas
write.csv(net_betas, file = paste(RAM_dir, 'group_analysis/win_', as.character(win), '/network_stats', detector, '.csv', sep=''))
write.csv(node_betas, file = paste(RAM_dir, 'group_analysis/win_', as.character(win), '/node_stats', detector, '.csv', sep=''))

```

Tests on betas

```{r}
net_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_data_clean', detector, '.csv',sep=''))
net_data$race = as.factor(net_data$race)
soz_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_soz_data_clean', detector ,'.csv',sep=''))
soz_data$race = as.factor(soz_data$race)
soz_data <- mutate(soz_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
spike_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_spike_data_clean', detector, '.csv',sep=''))
spike_data$race = as.factor(spike_data$race)
spike_data <- mutate(spike_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))

```

Are distributions of effect sizes different from 0?
```{r}
pred = 'bin' # bin or num
aec_flag = 'aec$' # which aec do you want to EXCLUDE, orth or regular. The carrot mean "ends with"

bfc = unique(net_data$band_measure)
bfc = bfc[!grepl(aec_flag, bfc)]
ps = list()
ts = list()
df = list()
for (m in bfc){
  print(m)
  curr <- filter(net_data, band_measure == m)
  stat <- t.test(curr[paste('str_beta_', pred, sep='')])
  print(stat)
  ps = c(ps, stat$p.value)
  ts = c(ts, stat$statistic)
  df = c(df, stat$parameter)
}

# corrections based on aec or aec_orth, not both
stats = data.frame(p = p.adjust(ps, method='bonferroni'), t = unlist(ts), df = unlist(df), measure = bfc, sig = p.adjust(ps, method="bonferroni") < 0.05)
stats

```

Is there a differences between orthogonalized AEC, and AEC?
```{r}
pred = 'bin'

# test for main effect of orthogonalization
amp = filter(net_data, fc_measure == 'aec' | fc_measure == 'aec_ortho')
bands = unique(amp$band)
aec_ps = list()
aec_ts = list()
aec_df = list()

for (m in bands){
  print(m)
  curr <- dplyr::filter(amp, band == m)
  if (pred == 'bin'){
    stat <- lmer(data=curr, str_beta_bin ~ fc_measure + (1|subj))
  } else {
    stat <- lmer(data=curr, str_beta_num ~ fc_measure + (1|subj))
  }
  print(anova(stat))
  aec_ps = c(aec_ps, anova(stat)$`Pr(>F)`[1])
  aec_ts = c(aec_ts, anova(stat)$`F value`[1])
  aec_df = c(aec_df, anova(stat)$DenDF[1])
}

aec_stats = data.frame(p = unlist(aec_ps), f = unlist(aec_ts), df = unlist(aec_df), band = bands, sigMC = p.adjust(aec_ps, method = 'bonferroni') < 0.05, sig = aec_ps < 0.05)
aec_stats
```

Do distributions of effect sizes differ within seizure onset zone vs outside of it?
```{r}
pred = 'bin'
aec_flag = 'aec$'

pred = paste('soz_beta_', pred, sep = '')
soz_bm = unique(soz_data$band_measure)
soz_bm = soz_bm[!grepl(aec_flag, soz_bm)]
soz_ps = list()
soz_ts = list()
soz_df = list()
for (m in soz_bm){
  print(m)
  curr <- dplyr::filter(soz_data, band_measure == m)
  within <- dplyr::filter(curr, SOZ == 'within') 
  within <- dplyr::select(within, pred)
  outside <- dplyr::filter(curr, SOZ == 'outside')
  outside <- dplyr::select(outside, pred)
  stat <- t.test(within[,1], outside[,1], paired=TRUE)
  print(stat)
  soz_ps = c(soz_ps, stat$p.value)
  soz_ts = c(soz_ts, stat$statistic)
  soz_df = c(soz_df, stat$parameter)
}

soz_stats = data.frame(p = unlist(soz_ps), t = unlist(soz_ts), df = unlist(soz_df), measure = soz_bm, sigMC = p.adjust(soz_ps, method="bonferroni") < 0.05, sig = unlist(soz_ps) < 0.05)
soz_stats

```

```{r}
pred = 'num'
aec_flag = 'aec$'

pred = paste('spike_beta_', pred, sep = '')
spike_bm = unique(spike_data$band_measure)
spike_bm = spike_bm[!grepl(aec_flag, spike_bm)]
spike_ps = list()
spike_ts = list()
spike_df = list()
for (m in spike_bm){
  print(m)
  curr <- dplyr::filter(spike_data, band_measure == m)
  within <- dplyr::filter(curr, spike == 'within') 
  within <- dplyr::select(within, pred)
  outside <- dplyr::filter(curr, spike == 'outside')
  outside <- dplyr::select(outside, pred)
  stat <- t.test(within[,1], outside[,1], paired=TRUE)
  print(stat)
  spike_ps = c(spike_ps, stat$p.value)
  spike_ts = c(spike_ts, stat$statistic)
  spike_df = c(spike_df, stat$parameter)
}

spike_stats = data.frame(p = unlist(spike_ps), t = unlist(spike_ts), df = unlist(spike_df), measure = spike_bm, sigMC = p.adjust(spike_ps, method="bonferroni") < 0.05, sig = unlist(spike_ps) < 0.05)
spike_stats

```

The rest of the stats are concerning parsing variability across indidividuals and channels
```{r}
keep_measures = c('aec_ortho', 'coh')
supp_measures = c('aec', 'plv', 'ar', 'xcorr')
```


 # Relationship with behavior
 
```{r}
 # general task performance
 pred = 'bin'
supp_flag = FALSE # are you using main measures, or supplemental measures

task_ps = list()
task_df = list()
task_ts = list()
tasks = c('TH', 'YC', 'PAL', 'FR', 'catFR')
net_task_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_task_data_clean', detector, '.csv', sep=''))
net_task_data = net_task_data[rowSums(is.na(net_task_data[,tasks])) <= 2,]
net_task_data$race = as.factor(net_task_data$race)
net_task_data <- mutate(net_task_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    net_task_data = dplyr::filter(net_task_data, Measure != m)
  }
}else {
  for (m in supp_measures){
    net_task_data = dplyr::filter(net_task_data, Measure != m)
  }
}
fc = unique(net_task_data$band_measure)
for (m in fc){
  print(m)
  curr = dplyr::filter(net_task_data, band_measure == m)
  # scale
  contrasts(curr$gender) <- contr.helmert(2)/2
  fit = lm(data=curr, paste('avg ~ str_beta_', pred, ' + race + gender + age + hand', sep=''))
  print(anova(fit))
  task_ps = c(task_ps, anova(fit)$`Pr(>F)`[1])
  task_ts = c(task_ts, anova(fit)$`F value`[1])
  task_df = c(task_df, anova(fit)$Df[2])
}

task_stats = data.frame(p = unlist(task_ps), f = unlist(task_ts), df = unlist(task_df), band_measure = fc, sigMC = p.adjust(task_ps, method = 'bonferroni') < 0.05, sig = task_ps < 0.05)
task_stats
```
 
```{r}
pred = 'bin'
task = 'nav' # nav or recall, individual tasks are TH, FR, catFR, PAL, YC
supp_flag = FALSE # are you using main measures, or supplemental measures

task_ps = list()
task_df = list()
task_ts = list()
tasks = c('TH', 'YC', 'PAL', 'FR', 'catFR')
net_task_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_task_data_clean', detector, '.csv', sep=''))
net_task_data = net_task_data[rowSums(is.na(net_task_data[,tasks])) <= 2,]
net_task_data$race = as.factor(net_task_data$race)
net_task_data <- mutate(net_task_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    net_task_data = dplyr::filter(net_task_data, Measure != m)
  }
}else {
  for (m in supp_measures){
    net_task_data = dplyr::filter(net_task_data, Measure != m)
  }
}
fc = unique(net_task_data$band_measure)
for (m in fc){
  print(m)
  curr = dplyr::filter(net_task_data, band_measure == m)
  # scale
  contrasts(curr$gender) <- contr.helmert(2)/2
  fit = lm(data=curr, paste(task, ' ~ str_beta_', pred, ' + race + gender + age + hand + avg', sep=''))
  print(anova(fit))
  task_ps = c(task_ps, anova(fit)$`Pr(>F)`[1])
  task_ts = c(task_ts, anova(fit)$`F value`[1])
  task_df = c(task_df, anova(fit)$Df[2])
}

task_stats = data.frame(p = unlist(task_ps), f = unlist(task_ts), df = unlist(task_df), band_measure = fc, sigMC = p.adjust(task_ps, method = 'bonferroni') < 0.05, sig = task_ps < 0.05)
task_stats
```

# With demographics

```{r}
pred = 'bin'
supp_flag = TRUE
idx = 1 # which demographic do you want to make plots for? use the index for the 'dems' list. 1 = race, 2 = gender, etc

dems = c('race', 'gender', 'hand', 'age')
dem_ps = list()
dem_ts = list()
dem_df = list()
curr = net_data
if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    curr = dplyr::filter(curr, fc_measure != m)
  }
}else {
  for (m in supp_measures){
    curr = dplyr::filter(curr, fc_measure != m)
  }
}
fc = unique(curr$band_measure)
for (m in fc){
  print(m)
  fit = lm(data=dplyr::filter(curr, band_measure == m), paste('str_beta_',pred,' ~ race + gender + hand + age',sep=''))
  print(anova(fit))
  dem_ps = c(dem_ps, anova(fit)$`Pr(>F)`[idx])
  dem_ts = c(dem_ts, anova(fit)$`F value`[idx])
  dem_df = c(dem_df, anova(fit)$Df[idx])
}
dem_stats = data.frame(dem = dems[idx], p = unlist(dem_ps), f = unlist(dem_ts), df = unlist(dem_df), band_measure = fc, sigMC = p.adjust(dem_ps, method = 'bonferroni') < 0.05, sig = dem_ps < 0.05)
dem_stats
```

# variability in soz hemisphere
```{r}
pred = 'bin'
supp_flag = FALSE # are you using main measures, or supplemental measures
flag = 'soz' # do you want to look at soz or spike

hem_ps = list()
hem_df = list()
hem_ts = list()
hem_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/sys_',flag, detector, '.csv', sep=''))
hem_data <- mutate(hem_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
hem_data$hem_hand[!((hem_data$hem_hand == 'i') | (hem_data$hem_hand == 'c'))] = NA

if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    hem_data = dplyr::filter(hem_data, Measure != m)
  }
}else {
  for (m in supp_measures){
    hem_data = dplyr::filter(hem_data, Measure != m)
  }
}
fc = unique(hem_data$band_measure)
for (m in fc){
  print(m)
  curr = dplyr::filter(hem_data, band_measure == m)
  if (pred == 'num'){
    fit = aovp(data=curr, str_beta_num ~ hem_hand + race + gender + age)
  } else {
    fit = aovp(data=curr, str_beta_bin ~ hem_hand + race + gender + age)
  }
  
  print(summary(fit))
  tmp <- summary(fit)
  hem_ps = c(hem_ps, summary(fit)[[1]]$`Pr(Prob)`[1])
  hem_ts = c(hem_ts, summary(fit)[[1]]$`R Mean Sq`[1])
  hem_df = c(hem_df, summary(fit)[[1]]$Df[1])
}

hem_stats = data.frame(p = unlist(hem_ps), f = unlist(hem_ts), df = unlist(hem_df), band_measure = fc, sigMC = p.adjust(hem_ps, method = 'bonferroni') < 0.05, sig = hem_ps < 0.05)
hem_stats

```
# variability in SOZ/spike location
```{r}
pred = 'bin'
supp_flag = FALSE # are you using main measures, or supplemental measures
flag = 'soz'

loc_ps = list()
loc_df = list()
loc_ts = list()
soz_loc_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/sys_',flag, detector, '.csv', sep=''))
soz_loc_data <- mutate(soz_loc_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    soz_loc_data = dplyr::filter(soz_loc_data, Measure != m)
  }
}else {
  for (m in supp_measures){
    soz_loc_data = dplyr::filter(soz_loc_data, Measure != m)
  }
}
fc = unique(soz_loc_data$band_measure)
for (m in fc){
  print(m)
  curr = dplyr::filter(soz_loc_data, band_measure == m)
  if (pred == 'num'){
    fit = aovp(data=curr, str_beta_num ~ locus + race + gender + hand + age)
  } else {
    fit = aovp(data=curr, str_beta_bin ~ locus + race + gender + hand + age)
  }
  print(summary(fit))
  loc_ps = c(loc_ps, summary(fit)[[1]]$`Pr(Prob)`[1])
  loc_ts = c(loc_ts, summary(fit)[[1]]$`R Mean Sq`[1])
  loc_df = c(loc_df, summary(fit)[[1]]$Df[1])
}

loc_stats = data.frame(p = unlist(loc_ps), f = unlist(loc_ts), df = unlist(loc_df), band_measure = fc, sigMC = p.adjust(loc_ps, method = 'bonferroni') < 0.05, sig = loc_ps < 0.05)
loc_stats

```


## Parsing Variability across regions

# aggregating over systems

```{r}

supp_flag = TRUE # is this analysis for the supplemental meausres, or the main ones
pred = 'num'

sys_ps = list()
sys_df = list()
sys_ndf = list()
sys_fs = list()
sys_data = read.csv(paste(RAM_dir, 'group_analysis/win_', as.character(win), '/sys_stats', detector, '.csv', sep=''))
sys_data <- mutate(sys_data, band_measure = paste(band, fc_measure, sep = '_'))
if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    sys_data = dplyr::filter(sys_data, fc_measure != m)
  }
}else {
  for (m in supp_measures){
    sys_data = dplyr::filter(sys_data, fc_measure != m)
  }
}

fc = unique(sys_data$band_measure)
for (m in fc){
  print(m)
  if (pred == 'bin'){
    fit = lmer(data=dplyr::filter(sys_data, band_measure == m), scale_bin ~ sys + (1|subj))
  } else {
    fit = lmer(data=dplyr::filter(sys_data, band_measure == m), scale_num ~ sys + (1|subj))
  }
  print(anova(fit))
  sys_ps = c(sys_ps, anova(fit)$`Pr(>F)`[1])
  sys_fs = c(sys_fs, anova(fit)$`F value`[1])
  sys_ndf = c(sys_ndf, anova(fit)$NumDF[1])
  sys_df = c(sys_df, anova(fit)$DenDF[1])
}

sys_stats = data.frame(p = unlist(sys_ps), f = unlist(sys_fs), ndf = unlist(sys_ndf), df = unlist(sys_df), band_measure = fc, sigMC = p.adjust(sys_ps, method = 'bonferroni') < 0.05, sig = sys_ps < 0.05)
sys_stats
```

# aggregating by electrode type
```{r}

supp_flag = TRUE # is this analysis for the supplemental meausres, or the main ones
pred = 'bin'

wm_ps = list()
wm_df = list()
wm_ndf = list()
wm_fs = list()
wm_data = read.csv(paste(RAM_dir, 'group_analysis/win_', as.character(win), '/type_stats', detector, '.csv', sep=''))
wm_data <- mutate(wm_data, band_measure = paste(band, fc_measure, sep = '_'))
if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    wm_data = dplyr::filter(wm_data, fc_measure != m)
  }
}else {
  for (m in supp_measures){
    wm_data = dplyr::filter(wm_data, fc_measure != m)
  }
}

fc = unique(sys_data$band_measure)
for (m in fc){
  print(m)
  if (pred == 'bin'){
    fit = lmer(data=dplyr::filter(wm_data, band_measure == m), str_beta_bin ~ type + (1|subj))
  } else {
    fit = lmer(data=dplyr::filter(wm_data, band_measure == m), str_beta_num ~ type + (1|subj))
  }
  print(anova(fit))
  wm_ps = c(wm_ps, anova(fit)$`Pr(>F)`[1])
  wm_fs = c(wm_fs, anova(fit)$`F value`[1])
  wm_ndf = c(wm_ndf, anova(fit)$NumDF[1])
  wm_df = c(wm_df, anova(fit)$DenDF[1])
}

wm_stats = data.frame(p = unlist(wm_ps), f = unlist(wm_fs), ndf = unlist(wm_ndf), df = unlist(wm_df), band_measure = fc, sigMC = p.adjust(wm_ps, method = 'bonferroni') < 0.05, sig = wm_ps < 0.05)
wm_stats
```

## EDA

```{python}
# imports
import numpy as np
import pandas as pd
import seaborn as sns

# directories
RAM_dir = '/Volumes/bassett-data/Jeni/RAM/'

# load data
net_data = pd.read_csv(RAM_dir + 'group_analysis/network_stats.csv')
node_data = pd.read_csv(RAM_dir + 'group_analysis/node_stats.csv')

node_data.head()
```
