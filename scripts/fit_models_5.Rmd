---
title: "Do Interictal Discharges Affect iEEG Functional Connectivity"
output: html_document
author: Jennifer Stiso
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# clean workspace
rm(list=ls())

if (!require("pacman")) install.packages("pacman")
pacman::p_load(ggplot2, dplyr, lm.beta, RColorBrewer, nationalparkcolors, rjson, reticulate, gridExtra, wesanderson, MASS, outliers, lmerTest, stringr, lmPerm)

# set up python for later
use_python("/Users/stiso/anaconda3/bin/python") # path to python binary
py_config() # check it is using the specified version

# directory for RAM data, request from XXX
RAM_dir = '/Volumes/bassett-data/Jeni/RAM/'

# parameters
win = 1
detector = ''

```

## Functions
```{r}
get_beta <- function(d, ys, f) {
  # fit models for every given predictor
  for (y in ys){
    # remove nan rows
    d_lm = d[!is.na(d[y]),]
  
    # check if multiple sess and exper
    if (length(unique(d_lm$sess_exper)) > 1) {
      f_full <- paste(f, 'sess_exper', sep = ' + ')
      # to prevent prevent factor level errors
      d_lm$sess_exper = as.factor(d_lm$sess_exper)
    } else {
      f_full <- f
    }
    
    beta_bin_name <- paste(y, 'beta_bin', sep = '_')
    beta_num_name <- paste(y, 'beta_num', sep = '_')
    beta_spr_name <- paste(y, 'beta_spr', sep = '_')
    if (dim(d_lm[y])[1] == 0){ # check for nans
      d[beta_bin_name] <- NaN
      d[beta_num_name] <- NaN
      d[beta_spr_name] <- NaN
    } else {

      # make spike a factor - prevent factor level errors
      d_lm$bin_spike <- as.factor(d_lm$bin_spike)
      # for debugging
      # print(paste(y, d_lm$band[1], d_lm$fc_measure[1], d_lm$region[1]))
      
      # fit
      # check for singular matrix (only two values for spike_num)
      cor_check1 = cor.test(d_lm$spike_num, d_lm$spike_spread) 
      cor_check2 = cor.test(d_lm$spike_num, as.numeric(d_lm$bin_spike))
      if (cor_check1$estimate != 1 & cor_check2$estimate != 1){
        f_full = paste(y, f_full, sep = '')
        try({invisible(fit <- lmp(as.formula(f_full), d_lm, singular.ok = FALSE))
        d[beta_bin_name] <- fit$coefficients['bin_spike1']
        d[beta_num_name] <- fit$coefficients['spike_num']
        d[beta_spr_name] <- fit$coefficients['spike_spread']})
      } else if (cor_check1$estimate == 1 & cor_check2$estimate != 1){
        f_full <- str_remove(f_full, fixed("+ spike_spread"))
        f_full = paste(y, f_full, sep = '')
        try({invisible(fit <- lmp(as.formula(f_full), d_lm, singular.ok = FALSE))
        d[beta_bin_name] <- fit$coefficients['bin_spike1']
        d[beta_num_name] <- fit$coefficients['spike_num']
        d[beta_spr_name] <- NaN})
      } else if (cor_check2$estimate == 1 & cor_check1$estimate != 1){
        f_full <- str_remove(f_full, fixed("+ bin_spike"))
        f_full = paste(y, f_full, sep = '')
        try({invisible(fit <- lmp(as.formula(f_full), d_lm, singular.ok = FALSE))
        d[beta_spr_name] <- fit$coefficients['spike_spread']
        d[beta_num_name] <- fit$coefficients['spike_num']
        d[beta_bin_name] <- NaN})
      } else {
        f_full <- str_remove(f_full, fixed("+ spike_num + spike_spread"))
        try({invisible(fit <- lmp(as.formula(paste(y, f_full, sep='')), d_lm, singular.ok = FALSE))
        d[beta_bin_name] <- fit$coefficients['bin_spike1']
        d[beta_num_name] <- NaN
        d[beta_spr_name] <- NaN})
      }
    }
  }
  return(d)
}
```

# Methods

words

## Load Data

```{r}
# get subjects from all releases
releases <- c('1', '2', '3')
subj <- list()
for (r in releases){
  curr_info <- paste(RAM_dir, 'release', r, '/protocols/r1.json', sep='')
  df <- rjson::fromJSON(file = curr_info)
  df <- names(df$protocols$r1$subjects) %>%
    lapply(function(x){paste('release', r, '/r1/', x, sep ='')})
  subj <- append(subj, df)
}

```

## Fit Models

```{r}
# Do we want to make plots? faster if no
save_plot = TRUE

# intiialize, make constants
# constant fields
const_vars <- c('subj', 'hand', 'age', 'gender', 'race')
form <- ' ~ power + bin_spike + spike_num + spike_spread'
ys = c('str', 'str_soz', 'str_not_soz', 'str_spike', 'str_not_spike', "ti")

# final df
col_names <- c("fc_measure", "band", 'band_measure', "str_beta_bin", "str_beta_num", "str_beta_spr", "ti_beta_bin", "ti_beta_num", "ti_beta_spr", "subj", "hand", "age", "gender", "race", 'n_tp')
net_betas <- data.frame(matrix(ncol = length(col_names), nrow = 0))
colnames(net_betas) = col_names
col_names = c("subj", "fc_measure", "band", 'band_measure', "str_soz_beta_bin", "str_not_soz_beta_bin", "str_spike_beta_bin", 
              "str_not_spike_beta_bin","str_soz_beta_num", "str_not_soz_beta_num", "str_spike_beta_num","str_soz_beta_spr","str_not_soz_beta_spr","str_spike_beta_spr", "str_not_spike_beta_spr", 'x', 'y', 'z', 'type',
              "str_not_spike_beta_num", "elec", "region", "n_tp", "elec_in_soz", "elec_spike", "age", "gender", "race", "hand" )
node_betas <- data.frame(matrix(ncol = length(col_names), nrow = 0))
colnames(node_betas) = col_names

# for each subject, load their data and fit some models
for (s in subj){
  # load strengths from matlab
  curr_csv <- paste(RAM_dir, 'FC/', s, '/win_', as.character(win), '/fc_data', detector, '.csv', sep = '')
  if (file.exists(curr_csv) ){
    node_data <- read.csv(curr_csv, header = TRUE, sep = ",", stringsAsFactors = FALSE,
                          colClasses=c(gender='character', hand='character', race='numeric', age='numeric', spike_num='numeric'))
    if (dim(node_data)[1] > 0){
      print(paste('Subj', s)) 
      # add band measure, combined string, for easy indexing (keep separate for plotting)
      node_data <- mutate(node_data, band_measure = paste(band, fc_measure, sep = '_'))
      # add sess_exper for model, dont actually want to model them separately
      node_data <- mutate(node_data, sess_exper = paste(sess, exper, sep = '_'))
      # add binary spike
      node_data$bin_spike = node_data$spike_num > 0
      # there shouldn't be any negative numbers, but if there are skip
      if (any(node_data$spike_num[complete.cases(node_data$spike_num)] < 0)){
        node_data$spike_num[node_data$spike_num < 0] = NaN
        warning("This dataset had negative spike numbers: check the spreadsheet")
        next
      }
      # there shouldn't be any NaNs, but if there are skip
      if (any(is.nan(node_data$spike_num)) | any(is.na(node_data$spike_num))){
        warning("This dataset had NaN spike numbers: check the spreadsheet")
        next
      }
      
      # drop hg phase locking - PLV not interpretable for wide band signals
      node_data <- filter(node_data, band_measure != "hg_plv")
      # remove duplicate time points, if present
      node_data <- node_data %>% distinct()
      
      # get network level strength separated by soz and not soz
      net_data <- group_by(node_data, sess_exper, time, spike_num, spike_spread, bin_spike, fc_measure, band, band_measure) %>%
        dplyr::summarise(str = mean(str, na.rm=TRUE), str_spike = mean(str_spike, na.rm=TRUE), 
                         str_not_spike = mean(str_not_spike, na.rm=TRUE), ti = mean(ti, na.rm=TRUE),  power = mean(power))
      # for soz networks, you can't average over all elecs, have to break them up
      tmp_soz = group_by(node_data, elec_in_soz, sess_exper, time, spike_num, bin_spike, spike_spread, fc_measure, band, band_measure) %>%
        dplyr::summarise(str_soz = mean(str_soz, na.rm=TRUE), str_not_soz = mean(str_not_soz, na.rm=TRUE))
      # remove not soz elecs from str_soz, and visa versa
      tmp_soz$str_soz[tmp_soz$elec_in_soz == 0] <- NA
      tmp_soz$str_not_soz[tmp_soz$elec_in_soz == 1] <- NA
      # now colapse over elec_in_soz
      tmp_soz <- group_by(node_data, sess_exper, time, spike_num, spike_spread, bin_spike, fc_measure, band, band_measure) %>%
        dplyr::summarise(str_soz = mean(str_soz, na.rm=TRUE), str_not_soz = mean(str_not_soz, na.rm=TRUE))
      # now merge on shared features (subj, band, time, etc)
      net_data = merge(net_data, tmp_soz, by = c('sess_exper', 'time', 'spike_num','spike_spread', 'bin_spike', "fc_measure", 'band', 'band_measure'))
      
      # add constants
      net_data[const_vars] = node_data[const_vars][1,]
      
      # plots
      if (save_plot){
          p1 <- ggplot(data=net_data[net_data$spike_num != 0,], aes(x=spike_num)) + geom_histogram() + theme_minimal()
          p2 <-ggplot(data=net_data[net_data$spike_spread != 0,], aes(x=spike_spread)) + geom_histogram() + theme_minimal()
          p3 <- ggplot(data=net_data[net_data$spike_num != 0,], aes(x=str, color=band, fill=as.factor(fc_measure))) + 
            geom_histogram(alpha=0.7) + theme_minimal() + scale_fill_manual(values=park_palette("GeneralGrant")) + scale_color_grey()
          p <- grid.arrange(p1, p2, p3, nrow=3)
          ggsave(paste(RAM_dir, 'img/models/', net_data$subj, '_net_hist.png', sep=''), plot=p, device = 'png')
      }
    
      # for every fc_meansure and band, fit network model
      try({
        curr_net_beta <- group_by(net_data, band_measure) %>%
          group_modify(~ get_beta(.x,ys, form)) %>%
          dplyr::summarise(n_tp = length(time), str_beta_bin = str_beta_bin[1], str_beta_num = 
                             str_beta_num[1], str_beta_spr = str_beta_spr[1], ti_beta_bin = 
                             ti_beta_bin[1], ti_beta_num = ti_beta_num[1], ti_beta_spr = ti_beta_spr[1], 
                           str_soz_beta_bin = str_soz_beta_bin[1],  str_soz_beta_num = 
                             str_soz_beta_num[1], str_soz_beta_spr = str_soz_beta_spr[1], 
                           str_not_soz_beta_num = str_not_soz_beta_num[1], str_spike_beta_num = 
                             str_spike_beta_num[1], str_not_soz_beta_spr = 
                             str_not_soz_beta_spr[1],str_not_soz_beta_bin = str_not_soz_beta_bin[1], 
                           str_spike_beta_bin = str_spike_beta_bin[1], str_spike_beta_spr = 
                             str_spike_beta_spr[1],str_not_spike_beta_bin = 
                             str_not_spike_beta_bin[1],fc_measure = fc_measure[1], str_not_spike_beta_num
                           = str_not_spike_beta_num[1], str_not_spike_beta_spr = 
                             = str_not_spike_beta_spr[1], band = band[1])
        curr_net_beta[const_vars] <- net_data[const_vars][1,]
        
        # concatenate
        net_betas <- suppressWarnings(bind_rows(curr_net_beta, net_betas)) # silence warnings about converting factors to strings
      })
  
      # fit node models
      try({
          curr_node_beta <- group_by(node_data, elec, band_measure) %>%
              group_modify(~ get_beta(.x,ys, form)) %>%
              dplyr::summarise(n_tp = length(time), elec_spike = mean(elec_has_spike), 
                               elec_in_soz = elec_in_soz[1], str_soz_beta_bin = str_soz_beta_bin[1], 
                               str_not_soz_beta_bin = str_not_soz_beta_bin[1], str_spike_beta_bin = 
                                 str_spike_beta_bin[1], str_not_spike_beta_bin = 
                                 str_not_spike_beta_bin[1], str_beta_bin = str_beta_bin[1], 
                               str_soz_beta_num = str_soz_beta_num[1], str_not_soz_beta_num = 
                                 str_not_soz_beta_num[1], str_spike_beta_num = str_spike_beta_num[1], 
                               str_beta_num = str_beta_num[1],str_not_spike_beta_num = 
                                 str_not_spike_beta_num[1], ti_beta_bin = ti_beta_bin[1], ti_beta_num = 
                                 ti_beta_num[1], ti_beta_spr = ti_beta_spr[1], str_beta_spr = 
                                 str_beta_spr[1], str_soz_beta_spr = str_soz_beta_spr[1], 
                               str_not_soz_beta_spr = str_not_soz_beta_spr[1], str_spike_beta_spr = 
                                 str_spike_beta_spr[1], str_not_spike_beta_spr = 
                                 str_not_spike_beta_spr[1], fc_measure = 
                                 fc_measure[1], band = band[1], region = region[1], x = x[1],
                               y = y[1], z = z[1], type = type[1])
            curr_node_beta[const_vars] <- net_data[const_vars][1,]
            
          #  concetenate
          node_betas <- suppressWarnings(bind_rows(curr_node_beta, node_betas)) # silence warnings about converting factors to strings
        })
     }
  }
}

# save betas
write.csv(net_betas, file = paste(RAM_dir, 'group_analysis/win_', as.character(win), '/network_stats', detector, '.csv', sep=''))
write.csv(node_betas, file = paste(RAM_dir, 'group_analysis/win_', as.character(win), '/node_stats', detector, '.csv', sep=''))

```

Tests on betas

```{r}
net_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_data_clean', detector, '.csv',sep=''))
net_data$race = as.factor(net_data$race)
soz_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_soz_data_clean', detector ,'.csv',sep=''))
soz_data$race = as.factor(soz_data$race)
soz_data <- mutate(soz_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
spike_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_spike_data_clean', detector, '.csv',sep=''))
spike_data$race = as.factor(spike_data$race)
spike_data <- mutate(spike_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))

```

Are distributions of effect sizes different from 0?
```{r}
pred = 'num'# bin or num
aec_flag = 'aec$' # which aec do you want to EXCLUDE, orth or regular. The carrot mean "starts with", $                      means 'ends with'
coh_flag = '^coh' # 

curr_measures = net_data[!grepl(aec_flag, net_data$Measure) & !grepl(coh_flag, net_data$Measure),'band_measure']
bfc = unique(curr_measures)
ps = list()
ts = list()
df = list()
for (m in bfc){
  print(m)
  curr <- filter(net_data, band_measure == m)
  stat <- t.test(curr[paste('str_beta_', pred, sep='')])
  print(stat)
  ps = c(ps, stat$p.value)
  ts = c(ts, stat$statistic)
  df = c(df, stat$parameter)
}

# corrections based on aec or aec_orth, not both
stats = data.frame(p = p.adjust(ps, method='bonferroni'), t = unlist(ts), df = unlist(df), measure = bfc, sig = p.adjust(ps, method="bonferroni") < 0.05)
stats

```

Is there a differences between orthogonalized AEC, and AEC, of coh and imaginary coh?
```{r}
pred = 'num'
m = 'coh'

# test for main effect of orthogonalization
if (m == 'aec'){
  amp = filter(net_data, Measure == 'aec' | Measure == 'aec_ortho')
} else {
  amp = filter(net_data, Measure == 'coh' | Measure == 'im_coh')
}

bands = unique(amp$Frequency.Band)
aec_ps = list()
aec_ts = list()
aec_df = list()

for (m in bands){
  print(m)
  curr <- dplyr::filter(amp, Frequency.Band == m)
  if (pred == 'bin'){
    stat <- lmer(data=curr, str_beta_bin ~ Measure + (1|subj))
  } else {
    stat <- lmer(data=curr, str_beta_num ~ Measure + (1|subj))
  }
  print(anova(stat))
  aec_ps = c(aec_ps, anova(stat)$`Pr(>F)`[1])
  aec_ts = c(aec_ts, anova(stat)$`F value`[1])
  aec_df = c(aec_df, anova(stat)$DenDF[1])
}

aec_stats = data.frame(p = unlist(aec_ps), f = unlist(aec_ts), df = unlist(aec_df), band = bands, sigMC = p.adjust(aec_ps, method = 'bonferroni') < 0.05, sig = aec_ps < 0.05)
aec_stats
```

Do distributions of effect sizes differ within seizure onset zone vs outside of it?
```{r}
pred = 'bin'
aec_flag = 'aec$' # which aec do you want to EXCLUDE, orth or regular. The carrot mean "starts with", $                      means 'ends with'
coh_flag = '^coh' # 

curr_measures = soz_data[!grepl(aec_flag, soz_data$Measure) & !grepl(coh_flag, soz_data$Measure),'band_measure']

pred = paste('soz_beta_', pred, sep = '')
soz_bm = unique(curr_measures)
soz_ps = list()
soz_ts = list()
soz_df = list()
for (m in soz_bm){
  print(m)
  curr <- dplyr::filter(soz_data, band_measure == m)
  within <- dplyr::filter(curr, SOZ == 'within') 
  within <- dplyr::select(within, pred)
  outside <- dplyr::filter(curr, SOZ == 'outside')
  outside <- dplyr::select(outside, pred)
  stat <- t.test(within[,1], outside[,1], paired=TRUE)
  print(stat)
  soz_ps = c(soz_ps, stat$p.value)
  soz_ts = c(soz_ts, stat$statistic)
  soz_df = c(soz_df, stat$parameter)
}

soz_stats = data.frame(p = unlist(soz_ps), t = unlist(soz_ts), df = unlist(soz_df), measure = soz_bm, sigMC = p.adjust(soz_ps, method="bonferroni") < 0.05, sig = unlist(soz_ps) < 0.05)
soz_stats

```

```{r}
pred = 'bin'
aec_flag = 'aec$' # which aec do you want to EXCLUDE, orth or regular. The carrot mean "starts with", $                      means 'ends with'
coh_flag = '^coh' # 

curr_measures = spike_data[!grepl(aec_flag, spike_data$Measure) & !grepl(coh_flag, spike_data$Measure),'band_measure']

pred = paste('spike_beta_', pred, sep = '')
spike_bm = unique(curr_measures)
spike_ps = list()
spike_ts = list()
spike_df = list()
for (m in spike_bm){
  print(m)
  curr <- dplyr::filter(spike_data, band_measure == m)
  within <- dplyr::filter(curr, spike == 'present') 
  within <- dplyr::select(within, pred)
  outside <- dplyr::filter(curr, spike == 'absent')
  outside <- dplyr::select(outside, pred)
  stat <- t.test(within[,1], outside[,1], paired=TRUE)
  print(stat)
  spike_ps = c(spike_ps, stat$p.value)
  spike_ts = c(spike_ts, stat$statistic)
  spike_df = c(spike_df, stat$parameter)
}

spike_stats = data.frame(p = unlist(spike_ps), t = unlist(spike_ts), df = unlist(spike_df), measure = spike_bm, sigMC = p.adjust(spike_ps, method="bonferroni") < 0.05, sig = unlist(spike_ps) < 0.05)
spike_stats

```

The rest of the stats are concerning parsing variability across indidividuals and channels
```{r}
net_data <-mutate(net_data, band_measure_clean = tolower(paste(Frequency.Band, Measure, sep = '_')))
keep_measures = c('theta_aec_ortho', 'lfp_ar', 'alpha_im_coh', 'beta_im_coh', 'gamma_im_coh')
bm = unique(net_data$band_measure_clean)
supp_measures = bm[which(!bm %in% keep_measures)]
```


 # Relationship with behavior

 
```{r}
 # general task performance
pred = 'num'
supp_flag = FALSE # are you using main measures, or supplemental measures

task_ps = list()
task_df = list()
task_ts = list()
tasks = c('TH', 'YC', 'PAL', 'FR', 'catFR')
net_task_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_task_data_clean', detector, '.csv', sep=''))
net_task_data$race <- as.factor(net_task_data$race)
net_task_data <- mutate(net_task_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
net_task_data$band_measure <- tolower(net_task_data$band_measure)
if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    net_task_data = dplyr::filter(net_task_data, band_measure != m)
  }
}else {
  for (m in supp_measures){
    net_task_data = dplyr::filter(net_task_data, band_measure != m)
  }
}
fc = unique(net_task_data$band_measure)
for (m in fc){
  print(m)
  curr = dplyr::filter(net_task_data, band_measure == m)
  curr = curr[!is.na(curr[,paste('str_beta_', pred, sep='')]),]
  nObs = dim(curr)[1]
  nRow = dim(resid)[1]
  fit = lm(data=curr, paste('avg ~ str_beta_', pred, '+ race + gender + age + hand + Etiology + Education + SeizureAge', sep=''))
  print(anova(fit))
      
  # get stats
  task_ps = c(task_ps, summary(fit)$coefficients[2,'Pr(>|t|)'])
  task_ts = c(task_ts, summary(fit)$coefficients[2,'t value'])
  task_df = c(task_df, summary(fit)$df[2])
}

task_stats = data.frame(p = unlist(task_ps), f = unlist(task_ts), df = unlist(task_df), band_measure = fc, sigMC = p.adjust(task_ps, method = 'bonferroni') < 0.05, sig = task_ps < 0.05)
task_stats
```


```{r}
resid = data.frame(subj = character(length=0), Measure = character(length=0), resid_num = numeric(0), resid_bin = numeric(0), Band = character(length=0), nav = numeric(0), recall = numeric(0), stringsAsFactors = FALSE)
```
```{r}
 # general task performance
pred = 'bin'

net_task_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_task_data_clean', detector, '.csv', sep=''))
net_task_data$race = as.factor(net_task_data$race)
net_task_data <- mutate(net_task_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))

fc = unique(net_task_data$band_measure)
for (m in fc){
  curr = dplyr::filter(net_task_data, band_measure == m)
  curr = curr[rowSums(is.na(curr[,c(paste('str_beta_', pred, sep=''),'Education','SeizureAge','Etiology')])) == 0,]
  nObs = dim(curr)[1]
  nRow = dim(resid)[1]
  # scale
  fit = lm(data=curr, paste('str_beta_', pred, ' ~ avg + race + gender + age + hand + Etiology + Education + SeizureAge', sep=''))

  # get residuals
  resid[(nRow+1):(nRow+nObs),'subj'] = as.character(curr$subj)
  resid[(nRow+1):(nRow+nObs),'Measure'] = as.character(curr$Measure)
  resid[(nRow+1):(nRow+nObs),'Band'] = as.character(curr$Frequency.Band)
  resid[(nRow+1):(nRow+nObs), 'nav'] = curr$scale_nav
  resid[(nRow+1):(nRow+nObs), 'recall'] = curr$recall
  if (pred == 'num'){
    resid[(nRow+1):(nRow+nObs), 'resid_num'] = fit$residuals
  } else {
    resid[(nRow+1):(nRow+nObs), 'resid_bin'] = fit$residuals
  }

}

```

```{r}
# save residuals for plots
write.csv(resid, file = paste(RAM_dir, 'group_analysis/win_', as.character(win), '/resid', detector, '.csv', sep=''))
```

```{r}
pred = 'bin'
task = 'nav' #nav or recall, individual tasks are TH, FR, catFR, PAL, YC
supp_flag = FALSE # are you using main measures, or supplemental measures

task_ps = list()
task_df = list()
task_ts = list()
tasks = c('TH', 'YC', 'PAL', 'FR', 'catFR')
net_task_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_task_data_clean', detector, '.csv', sep=''))
net_task_data$race = as.factor(net_task_data$race)
net_task_data <- mutate(net_task_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
net_task_data$band_measure <- tolower(net_task_data$band_measure)
if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    net_task_data = dplyr::filter(net_task_data, band_measure != m)
  }
}else {
  for (m in supp_measures){
    net_task_data = dplyr::filter(net_task_data, band_measure != m)
  }
}
fc = unique(net_task_data$band_measure)
for (m in fc){
  print(m)
  curr = dplyr::filter(net_task_data, band_measure == m)
  # scale
  contrasts(curr$gender) <- contr.helmert(2)/2
  fit = lm(data=curr, paste(task, ' ~ str_beta_', pred, ' + race + gender + age + hand + avg + Etiology + SeizureAge + Education', sep=''))
  print(anova(fit))
  task_ps = c(task_ps, summary(fit)$coefficients[2,'Pr(>|t|)'])
  task_ts = c(task_ts, summary(fit)$coefficients[2,'t value'])
  task_df = c(task_df, summary(fit)$df[2])
}

task_stats = data.frame(p = unlist(task_ps), f = unlist(task_ts), df = unlist(task_df), band_measure = fc, sigMC = p.adjust(task_ps, method = 'bonferroni') < 0.05, sig = task_ps < 0.05)
task_stats
```



# With demographics

```{r}
pred = 'num'
supp_flag = FALSE
idx = 4 # which demographic do you want to make plots for? use the index for the 'dems' list. 1 = race, 2 = gender, etc

dems = c('race', 'gender', 'hand', 'age')
dem_ps = list()
dem_ts = list()
dem_df = list()
curr = net_data
if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    curr = dplyr::filter(curr, band_measure_clean != m)
  }
}else {
  for (m in supp_measures){
    curr = dplyr::filter(curr, band_measure_clean != m)
  }
}
fc = unique(curr$band_measure)
for (m in fc){
  print(m)
  fit = lm(data=dplyr::filter(curr, band_measure == m), paste('str_beta_',pred,' ~ race + gender + hand + age',sep=''))
  print(anova(fit))
  dem_ps = c(dem_ps, anova(fit)$`Pr(>F)`[idx])
  dem_ts = c(dem_ts, anova(fit)$`F value`[idx])
  dem_df = c(dem_df, anova(fit)$Df[idx])
}
dem_stats = data.frame(dem = dems[idx], p = unlist(dem_ps), f = unlist(dem_ts), df = unlist(dem_df), band_measure = fc, sigMC = p.adjust(dem_ps, method = 'bonferroni') < 0.05, sig = dem_ps < 0.05)
dem_stats
```

# variability in soz hemisphere
```{r}
pred = 'num'
supp_flag = FALSE # are you using main measures, or supplemental measures
flag = 'spike' # do you want to look at soz or spike

hem_ps = list()
hem_df = list()
hem_ts = list()
hem_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/sys_',flag, detector, '.csv', sep=''))
hem_data <- mutate(hem_data, band_measure = tolower(paste(Frequency.Band, Measure, sep = '_')))
hem_data$hem_hand[!((hem_data$hem_hand == 'i') | (hem_data$hem_hand == 'c'))] = NA

if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    hem_data = dplyr::filter(hem_data, band_measure != m)
  }
}else {
  for (m in supp_measures){
    hem_data = dplyr::filter(hem_data, band_measure != m)
  }
}
fc = unique(hem_data$band_measure)
for (m in fc){
  print(m)
  curr = dplyr::filter(hem_data, band_measure == m)
  if (pred == 'num'){
    fit = aovp(data=curr, str_beta_num ~ hem_hand + race + gender + age)
  } else {
    fit = aovp(data=curr, str_beta_bin ~ hem_hand + race + gender + age)
  }
  
  print(summary(fit))
  tmp <- summary(fit)
  hem_ps = c(hem_ps, summary(fit)[[1]]$`Pr(Prob)`[1])
  hem_ts = c(hem_ts, summary(fit)[[1]]$`R Mean Sq`[1])
  hem_df = c(hem_df, summary(fit)[[1]]$Df[1])
}

hem_stats = data.frame(p = unlist(hem_ps), f = unlist(hem_ts), df = unlist(hem_df), band_measure = fc, sigMC = p.adjust(hem_ps, method = 'bonferroni') < 0.05, sig = hem_ps < 0.05)
hem_stats

```
# variability in SOZ/spike location
```{r}
pred = 'bin'
supp_flag = FALSE # are you using main measures, or supplemental measures
flag = 'spike'

loc_ps = list()
loc_df = list()
loc_ts = list()
soz_loc_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/sys_',flag, detector, '.csv', sep=''))
soz_loc_data <- mutate(soz_loc_data, band_measure = tolower(paste(Frequency.Band, Measure, sep = '_')))
if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    soz_loc_data = dplyr::filter(soz_loc_data, band_measure != m)
  }
}else {
  for (m in supp_measures){
    soz_loc_data = dplyr::filter(soz_loc_data, band_measure != m)
  }
}
fc = unique(soz_loc_data$band_measure)
for (m in fc){
  print(m)
  curr = dplyr::filter(soz_loc_data, band_measure == m)
  if (pred == 'num'){
    fit = aovp(data=curr, str_beta_num ~ locus + race + gender + hand + age)
  } else {
    fit = aovp(data=curr, str_beta_bin ~ locus + race + gender + hand + age)
  }
  print(summary(fit))
  loc_ps = c(loc_ps, summary(fit)[[1]]$`Pr(Prob)`[1])
  loc_ts = c(loc_ts, summary(fit)[[1]]$`R Mean Sq`[1])
  loc_df = c(loc_df, summary(fit)[[1]]$Df[1])
}

loc_stats = data.frame(p = unlist(loc_ps), f = unlist(loc_ts), df = unlist(loc_df), band_measure = fc, sigMC = p.adjust(loc_ps, method = 'bonferroni') < 0.05, sig = loc_ps < 0.05)
loc_stats

```
## Pathology
# lesional vs nonlesional
```{r}
pred = 'num'
supp_flag = FALSE # are you using main measures, or supplemental measures

les_ps = list()
les_df = list()
les_ts = list()
les_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/clinical', detector, '.csv', sep=''))
les_data <- mutate(les_data, band_measure = tolower(paste(Frequency.Band, Measure, sep = '_')))

if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    les_data = dplyr::filter(les_data, band_measure != m)
  }
}else {
  for (m in supp_measures){
    les_data = dplyr::filter(les_data, band_measure != m)
  }
}
fc = unique(les_data$band_measure)
for (m in fc){
  print(m)
  curr = dplyr::filter(les_data, band_measure == m)
  if (pred == 'num'){
    fit = aovp(data=curr, str_beta_num ~ Leisional + race + gender + age)
  } else {
    fit = aovp(data=curr, str_beta_bin ~ Lesional + race + gender + age)
  }
  
  print(summary(fit))
  tmp <- summary(fit)
  les_ps = c(les_ps, summary(fit)[[1]]$`Pr(Prob)`[1])
  les_ts = c(les_ts, summary(fit)[[1]]$`R Mean Sq`[1])
  les_df = c(les_df, summary(fit)[[1]]$Df[1])
}

les_stats = data.frame(p = unlist(les_ps), f = unlist(les_ts), df = unlist(les_df), band_measure = fc, sigMC = p.adjust(les_ps, method = 'bonferroni') < 0.05, sig = les_ps < 0.05)
les_stats

```

# etiology
```{r}
pred = 'bin'
supp_flag = FALSE # are you using main measures, or supplemental measures

clin_ps = list()
clin_df = list()
clin_ts = list()
clin_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/clinical', detector, '.csv', sep=''))
clin_data <- mutate(clin_data, band_measure = tolower(paste(Frequency.Band, Measure, sep = '_')))
# drop categories that have less than 10 people
value_counts = as.data.frame(table(clin_data[clin_data$band_measure == 'alpha_aec',]$Etiology))
idx = value_counts$Freq > 5
keep_vars = value_counts[idx,'Var1']
clin_data = clin_data[unlist(lapply(clin_data$Etiology, function(x) any(grepl(x, keep_vars)))),]
# remove 'unkown'
clin_data = dplyr::filter(clin_data, Etiology != 'Unkown')
if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    clin_data = dplyr::filter(clin_data, band_measure != m)
  }
}else {
  for (m in supp_measures){
    clin_data = dplyr::filter(clin_data, band_measure != m)
  }
}
fc = unique(clin_data$band_measure)
for (m in fc){
  print(m)
  curr = dplyr::filter(clin_data, band_measure == m)
  if (pred == 'num'){
    fit = aovp(data=curr, str_beta_num ~ Etiology + race + gender + age)
  } else {
    fit = aovp(data=curr, str_beta_bin ~ Etiology + race + gender + age)
  }
  
  print(summary(fit))
  tmp <- summary(fit)
  clin_ps = c(clin_ps, summary(fit)[[1]]$`Pr(Prob)`[1])
  clin_ts = c(clin_ts, summary(fit)[[1]]$`R Mean Sq`[1])
  clin_df = c(clin_df, summary(fit)[[1]]$Df[1])
}

clin_stats = data.frame(p = unlist(clin_ps), f = unlist(clin_ts), df = unlist(clin_df), band_measure = fc, sigMC = p.adjust(clin_ps, method = 'bonferroni') < 0.05, sig = clin_ps < 0.05)
clin_stats

```



## Parsing Variability across regions

# aggregating over systems

```{r}

supp_flag = FALSE # is this analysis for the supplemental meausres, or the main ones
pred = 'num'

sys_ps = list()
sys_df = list()
sys_ndf = list()
sys_fs = list()
sys_data = read.csv(paste(RAM_dir, 'group_analysis/win_', as.character(win), '/sys_stats', detector, '.csv', sep=''))
sys_data <- mutate(sys_data, band_measure = tolower(paste(band, fc_measure, sep = '_')))
if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    sys_data = dplyr::filter(sys_data, band_measure != m)
  }
}else {
  for (m in supp_measures){
    sys_data = dplyr::filter(sys_data, band_measure != m)
  }
}

fc = unique(sys_data$band_measure)
for (m in fc){
  print(m)
  if (pred == 'bin'){
    fit = lmer(data=dplyr::filter(sys_data, band_measure == m), scale_bin ~ sys + (1|subj))
  } else {
    fit = lmer(data=dplyr::filter(sys_data, band_measure == m), scale_num ~ sys + (1|subj))
  }
  print(anova(fit))
  sys_ps = c(sys_ps, anova(fit)$`Pr(>F)`[1])
  sys_fs = c(sys_fs, anova(fit)$`F value`[1])
  sys_ndf = c(sys_ndf, anova(fit)$NumDF[1])
  sys_df = c(sys_df, anova(fit)$DenDF[1])
}

sys_stats = data.frame(p = unlist(sys_ps), f = unlist(sys_fs), ndf = unlist(sys_ndf), df = unlist(sys_df), band_measure = fc, sigMC = p.adjust(sys_ps, method = 'bonferroni') < 0.05, sig = sys_ps < 0.05)
sys_stats
```

# aggregating by electrode type
```{r}

supp_flag = FALSE # is this analysis for the supplemental meausres, or the main ones
pred = 'bin'

wm_ps = list()
wm_df = list()
wm_ndf = list()
wm_fs = list()
wm_data = read.csv(paste(RAM_dir, 'group_analysis/win_', as.character(win), '/type_stats', detector, '.csv', sep=''))
wm_data <- mutate(wm_data, band_measure = paste(band, fc_measure, sep = '_'))
if (supp_flag){
  # loop through other measures and remove...probably a better way to do this
  for (m in keep_measures){
    wm_data = dplyr::filter(wm_data, band_measure != m)
  }
}else {
  for (m in supp_measures){
    wm_data = dplyr::filter(wm_data, band_measure != m)
  }
}

fc = unique(sys_data$band_measure)
for (m in fc){
  print(m)
  if (pred == 'bin'){
    fit = lmer(data=dplyr::filter(wm_data, band_measure == m), str_beta_bin ~ type + (1|subj))
  } else {
    fit = lmer(data=dplyr::filter(wm_data, band_measure == m), str_beta_num ~ type + (1|subj))
  }
  print(anova(fit))
  wm_ps = c(wm_ps, anova(fit)$`Pr(>F)`[1])
  wm_fs = c(wm_fs, anova(fit)$`F value`[1])
  wm_ndf = c(wm_ndf, anova(fit)$NumDF[1])
  wm_df = c(wm_df, anova(fit)$DenDF[1])
}

wm_stats = data.frame(p = unlist(wm_ps), f = unlist(wm_fs), ndf = unlist(wm_ndf), df = unlist(wm_df), band_measure = fc, sigMC = p.adjust(wm_ps, method = 'bonferroni') < 0.05, sig = wm_ps < 0.05)
wm_stats
```

## EDA

```{python}
# imports
import numpy as np
import pandas as pd
import seaborn as sns

# directories
RAM_dir = '/Volumes/bassett-data/Jeni/RAM/'

# load data
net_data = pd.read_csv(RAM_dir + 'group_analysis/network_stats.csv')
node_data = pd.read_csv(RAM_dir + 'group_analysis/node_stats.csv')

node_data.head()
```
